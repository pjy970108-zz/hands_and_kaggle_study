{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"LANGUAGE MODELING WITH NN.TRANSFORMER AND TORCHTEXT.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMiyXblDVJuE6EuNmD4sjo1"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"Z_bdICdVDaQ6"},"source":["# Transformer 모듈\n","\n","이번 장에서는 language modeling task에 대해서 배운다. \n","<br>\n","\n","일련의 단어를 따르는 단어가 주어졌을때 우도의 확률에 대한 task이다.\n","\n","<br>\n","\n","sequence token이 우선 embedding layer를 우선 통과하고 뒤이어 positional encoding layer를 통과한다.  <br>\n","인코더는 TransformerEncoding layers로 이루어짐\n","square attention mask는 self-attention때문에 요구된다. 이 mask는 encoder이전의 위치에만 참고 가능함. <br>\n","\n","모델링의 경우 모든 토큰은 마스킹을 해야한다. "]},{"cell_type":"code","metadata":{"id":"Gcy3wjenCfxT","executionInfo":{"status":"ok","timestamp":1636875238384,"user_tz":-540,"elapsed":279,"user":{"displayName":"부계정박준영","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13767636744278294407"}}},"source":["import math\n","from typing import Tuple\n","\n","import torch\n","from torch import nn, Tensor\n","import torch.nn.functional as F\n","from torch.nn import TransformerEncoder, TransformerEncoderLayer\n","from torch.utils.data import dataset\n","\n","class TransformerModel(nn.Module):\n","    def __init__(self, ntoken : int, d_model : int, nhead:int, d_hid : int, nlayers : int, dropout : float = 0.5):\n","      super().__init__()\n","      self.model_type = 'Transformer'\n","      self.pos_encoder = PositionalEncoding(d_model, dropout)\n","      encoder_layers = TransformerEncoderLayer(d_model, nhead, d_hid, dropout)\n","      self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n","      self.encoder = nn.Embedding(ntoken, d_model)\n","      self.d_model = d_model\n","      self.decoder = nn.Linear(d_model, ntoken)\n","      self.init_weights()  \n","\n","    def init_weights(self) -> None:\n","      initrange = 0.1\n","      self.encoder.weight.data.uniform_(-initrange, initrange) # 가중치 범위\n","      self.decoder.bias.data.zero_()\n","      self.decoder.weight.data.uniform_(-initrange, initrange)\n","\n","    def forward(self, src:Tensor, src_mask : Tensor) -> Tensor:\n","      # src : Tensor, shape [seq_len, batch_size]\n","      # src_mask : Tensor, shape [seq_len, seq_len]\n","      # output : [seq_len, batchsize, ntoken]\n","\n","        src = self.encoder(src) * math.sqrt(self.d_model)\n","        src = self.pos_encoder(src)\n","        output = self.transformer_encoder(src, src_mask)\n","        output = self.decoder(output)\n","        return output\n","\n","def generate_square_subsequent_mask(sz : int) -> Tensor:\n","  # triangular matrix 생성, 대각선은 0\"\n","  return torch.triu(torch.ones(sz, sz)*float('-inf'), diagonal=1)\n","\n","\n","# positional encoding은 토큰의 절대위치나 비교되는 위치를 넣는다. embedding과 차원은 같아 합칠수 있다.\n","# sine, cosine 함수를 사용\n","\n","\n","class PositionalEncoding(nn.Module):\n","  def __init__(self, d_model:int, dropout:float=0.1, max_len:int = 5000):\n","    super().__init__()\n","    self.dropout = nn.Dropout(p=dropout)\n","    position = torch.arange(max_len).unsqueeze(1)\n","    div_term = torch.exp(torch.arange(0, d_model, 2)*(-math.log(10000.0)/d_model))\n","    pe = torch.zeros(max_len, 1, d_model)\n","    pe[:, 0, 0::2] = torch.sin(position*div_term)\n","    pe[:, 0, 1::2] = torch.cos(position*div_term)\n","    self.register_buffer('pe', pe)\n","\n","\n","    def forward(self, x:Tensor)->Tensor:\n","      # x : [seq_len, batch_size, embedding_Dim]\n","\n","      x = x+self.pe[:x.size(0)] # potision 정보를 주입\n","      return self.dropout(X)\n","\n","\n"],"execution_count":42,"outputs":[]},{"cell_type":"code","metadata":{"id":"LNizewyhLomx","executionInfo":{"status":"ok","timestamp":1636875411620,"user_tz":-540,"elapsed":4457,"user":{"displayName":"부계정박준영","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13767636744278294407"}}},"source":["# 배치의 경우 모델은 각각의 컬럼을 독자적으로 학습한다. 그래서 전체적으로 학습 불가\n","\n","from torchtext.datasets import WikiText2\n","from torchtext.data.utils import get_tokenizer\n","from torchtext.vocab import build_vocab_from_iterator\n","\n","\n","train_iter = WikiText2(split='train')\n","tokenizer = get_tokenizer('basic_english')\n","vocab = build_vocab_from_iterator(map(tokenizer, train_iter), specials=['<unk>'])\n","vocab.set_default_index(vocab['<unk>'])\n","\n","def data_process(raw_text_iter : dataset.IterableDataset) -> Tensor:\n","  \"tensor로 변경\"\n","  data = [torch.tensor(vocab(tokenizer(item)), dtype=torch.long) for item in raw_text_iter]\n","  return torch.cat(tuple(filter(lambda t:t.numel()>0, data)))\n","\n","# train_iter의 경우 전처리과정에서 소비됨, 다시 만들어줌\n","train_iter, val_iter, test_iter = WikiText2()\n","train_data=data_process(train_iter)\n","val_data=data_process(val_iter)\n","test_data=data_process(test_iter)\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","def batchify(data:Tensor, bsz:int) -> Tensor:\n","  # bsz 만큼 시퀀스를 나누고 나머지 버림\n","  # data : shape [N]\n","  # bsz : batchsize\n","  # return Tensor of shape[N//bsz, bsz]\n","\n","  seq_len = data.size(0) // bsz\n","  data = data[:seq_len * bsz]\n","  data = data.view(bsz, seq_len).t().contiguous()\n","  return data.to(device)\n","\n","batch_size = 20\n","eval_batch_size = 10\n","train_data = batchify(train_data, batch_size)  \n","val_data = batchify(val_data, eval_batch_size)\n","test_data = batchify(test_data, eval_batch_size)"],"execution_count":54,"outputs":[]},{"cell_type":"code","metadata":{"id":"z3RHhe_fLoj-","executionInfo":{"status":"ok","timestamp":1636875414484,"user_tz":-540,"elapsed":359,"user":{"displayName":"부계정박준영","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13767636744278294407"}}},"source":["# input\n","bptt = 35\n","def get_batch(source:Tensor, i:int) -> Tuple[Tensor, Tensor]:\n","  # source [full_seq_len, batch_size]\n","  # i : int\n","  # tuple(data, target)\n","  seq_len = min(bptt, len(source)-1-i)\n","  data=source[i:i+seq_len]\n","  target=source[i+1:i+1+seq_len].reshape(-1)\n","  return data, target"],"execution_count":55,"outputs":[]},{"cell_type":"code","metadata":{"id":"rm_4Cy0TLoes","executionInfo":{"status":"ok","timestamp":1636875415891,"user_tz":-540,"elapsed":268,"user":{"displayName":"부계정박준영","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13767636744278294407"}}},"source":["ntokens=len(vocab)\n","emsize=200\n","d_hid=200\n","nlayers=2\n","nhead=2\n","dropout=0.2\n","model=TransformerModel(ntokens, emsize, nhead, d_hid, nlayers, dropout).to(device)"],"execution_count":56,"outputs":[]},{"cell_type":"code","metadata":{"id":"vaOtQykrRZKe","executionInfo":{"status":"ok","timestamp":1636875416772,"user_tz":-540,"elapsed":296,"user":{"displayName":"부계정박준영","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13767636744278294407"}}},"source":["# run model\n","import copy\n","import time\n","\n","criterion = nn.CrossEntropyLoss()\n","lr = 5.0  # learning rate\n","optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n","scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.95)\n","\n","def train(model: nn.Module) -> None:\n","    model.train()  \n","    total_loss = 0.\n","    log_interval = 200\n","    start_time = time.time()\n","    src_mask = generate_square_subsequent_mask(bptt).to(device)\n","\n","    num_batches = len(train_data) // bptt\n","    for batch, i in enumerate(range(0, train_data.size(0) - 1, bptt)):\n","        data, targets = get_batch(train_data, i)\n","        batch_size = data.size(0)\n","        if batch_size != bptt:  \n","            src_mask = src_mask[:batch_size, :batch_size]\n","        output = model(data, src_mask)\n","        loss = criterion(output.view(-1, ntokens), targets)\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n","        optimizer.step()\n","\n","        total_loss += loss.item()\n","        if batch % log_interval == 0 and batch > 0:\n","            lr = scheduler.get_last_lr()[0]\n","            ms_per_batch = (time.time() - start_time) * 1000 / log_interval\n","            cur_loss = total_loss / log_interval\n","            ppl = math.exp(cur_loss)\n","            print(f'| epoch {epoch:3d} | {batch:5d}/{num_batches:5d} batches | '\n","                  f'lr {lr:02.2f} | ms/batch {ms_per_batch:5.2f} | '\n","                  f'loss {cur_loss:5.2f} | ppl {ppl:8.2f}')\n","            total_loss = 0\n","            start_time = time.time()\n","\n","def evaluate(model: nn.Module, eval_data: Tensor) -> float:\n","    model.eval() \n","    total_loss = 0.\n","    src_mask = generate_square_subsequent_mask(bptt).to(device)\n","    with torch.no_grad():\n","        for i in range(0, eval_data.size(0) - 1, bptt):\n","            data, targets = get_batch(eval_data, i)\n","            batch_size = data.size(0)\n","            if batch_size != bptt:\n","                src_mask = src_mask[:batch_size, :batch_size]\n","            output = model(data, src_mask)\n","            output_flat = output.view(-1, ntokens)\n","            total_loss += batch_size * criterion(output_flat, targets).item()\n","    return total_loss / (len(eval_data) - 1)"],"execution_count":57,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":887},"id":"lq2W-R_WUype","executionInfo":{"status":"error","timestamp":1636875435800,"user_tz":-540,"elapsed":335,"user":{"displayName":"부계정박준영","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13767636744278294407"}},"outputId":"2c2fe4ed-07f3-4488-a396-3dea33b54889"},"source":["best_val_loss = float('inf')\n","epochs = 3\n","best_model = None\n","\n","for epoch in range(1, epochs + 1):\n","    epoch_start_time = time.time()\n","    train(model)\n","    val_loss = evaluate(model, val_data)\n","    val_ppl = math.exp(val_loss)\n","    elapsed = time.time() - epoch_start_time\n","    print('-' * 89)\n","    print(f'| end of epoch {epoch:3d} | time: {elapsed:5.2f}s | '\n","          f'valid loss {val_loss:5.2f} | valid ppl {val_ppl:8.2f}')\n","    print('-' * 89)\n","\n","    if val_loss < best_val_loss:\n","        best_val_loss = val_loss\n","        best_model = copy.deepcopy(model)\n","\n","    scheduler.step()\n","\n"],"execution_count":59,"outputs":[{"output_type":"error","ename":"NotImplementedError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-59-5af124aa6360>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mepoch_start_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mval_ppl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-57-f046e2f36f79>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mbptt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0msrc_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mntokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-42-fe569b1a95ae>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, src_mask)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0md_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_forward_unimplemented\u001b[0;34m(self, *input)\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0mregistered\u001b[0m \u001b[0mhooks\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mlatter\u001b[0m \u001b[0msilently\u001b[0m \u001b[0mignores\u001b[0m \u001b[0mthem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \"\"\"\n\u001b[0;32m--> 201\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNotImplementedError\u001b[0m: "]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":365},"id":"x7zfe3aHVrfk","executionInfo":{"status":"error","timestamp":1636875308564,"user_tz":-540,"elapsed":278,"user":{"displayName":"부계정박준영","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13767636744278294407"}},"outputId":"4e2a2b7d-27df-4085-8f7b-d6eb00a6ea3f"},"source":["test_loss = evaluate(best_model, test_data)\n","test_ppl = math.exp(test_loss)\n","print('=' * 89)\n","print(f'| End of training | test loss {test_loss:5.2f} | '\n","      f'test ppl {test_ppl:8.2f}')\n","print('=' * 89)"],"execution_count":50,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-50-1e5742a8615b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest_ppl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'='\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m89\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m print(f'| End of training | test loss {test_loss:5.2f} | '\n\u001b[1;32m      5\u001b[0m       f'test ppl {test_ppl:8.2f}')\n","\u001b[0;32m<ipython-input-48-9b69a44d2f47>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(model, eval_data)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_data\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m     \u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0msrc_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_square_subsequent_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbptt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'eval'"]}]},{"cell_type":"code","metadata":{"id":"ImHRC47FW-1_"},"source":[""],"execution_count":null,"outputs":[]}]}