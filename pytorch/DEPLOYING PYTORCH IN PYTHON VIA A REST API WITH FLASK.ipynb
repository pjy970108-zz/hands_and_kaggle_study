{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DEPLOYING PYTORCH IN PYTHON VIA A REST API WITH FLASK.ipynb","provenance":[{"file_id":"1FQvBJe70Rys0vZrL1DEP4s7vr00aMxx2","timestamp":1638689183657},{"file_id":"1LqxIG-ah6ru2HSVMBBI6JUtNyWbd1K_E","timestamp":1638686512313}],"collapsed_sections":[],"authorship_tag":"ABX9TyPBS5n2N8Pl+RMMc1Nwkiki"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"L2nFRJ09hwx1"},"source":["# Flask를 활용한 매포"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZgDzzBK9hsKf","executionInfo":{"status":"ok","timestamp":1638690115213,"user_tz":-540,"elapsed":199487,"user":{"displayName":"부계정박준영","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13767636744278294407"}},"outputId":"ef560c2b-eb9f-4237-a95e-4a6c502541e6"},"source":["# !pip install Flask==2.0.1 torchvision==0.10.0"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting Flask==2.0.1\n","  Downloading Flask-2.0.1-py3-none-any.whl (94 kB)\n","\u001b[K     |████████████████████████████████| 94 kB 2.3 MB/s \n","\u001b[?25hCollecting torchvision==0.10.0\n","  Downloading torchvision-0.10.0-cp37-cp37m-manylinux1_x86_64.whl (22.1 MB)\n","\u001b[K     |████████████████████████████████| 22.1 MB 1.8 MB/s \n","\u001b[?25hRequirement already satisfied: click>=7.1.2 in /usr/local/lib/python3.7/dist-packages (from Flask==2.0.1) (7.1.2)\n","Collecting itsdangerous>=2.0\n","  Downloading itsdangerous-2.0.1-py3-none-any.whl (18 kB)\n","Collecting Jinja2>=3.0\n","  Downloading Jinja2-3.0.3-py3-none-any.whl (133 kB)\n","\u001b[K     |████████████████████████████████| 133 kB 45.3 MB/s \n","\u001b[?25hCollecting Werkzeug>=2.0\n","  Downloading Werkzeug-2.0.2-py3-none-any.whl (288 kB)\n","\u001b[K     |████████████████████████████████| 288 kB 37.6 MB/s \n","\u001b[?25hRequirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.10.0) (7.1.2)\n","Collecting torch==1.9.0\n","  Downloading torch-1.9.0-cp37-cp37m-manylinux1_x86_64.whl (831.4 MB)\n","\u001b[K     |████████████████████████████████| 831.4 MB 2.6 kB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision==0.10.0) (1.19.5)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.0->torchvision==0.10.0) (3.10.0.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=3.0->Flask==2.0.1) (2.0.1)\n","Installing collected packages: Werkzeug, torch, Jinja2, itsdangerous, torchvision, Flask\n","  Attempting uninstall: Werkzeug\n","    Found existing installation: Werkzeug 1.0.1\n","    Uninstalling Werkzeug-1.0.1:\n","      Successfully uninstalled Werkzeug-1.0.1\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.10.0+cu111\n","    Uninstalling torch-1.10.0+cu111:\n","      Successfully uninstalled torch-1.10.0+cu111\n","  Attempting uninstall: Jinja2\n","    Found existing installation: Jinja2 2.11.3\n","    Uninstalling Jinja2-2.11.3:\n","      Successfully uninstalled Jinja2-2.11.3\n","  Attempting uninstall: itsdangerous\n","    Found existing installation: itsdangerous 1.1.0\n","    Uninstalling itsdangerous-1.1.0:\n","      Successfully uninstalled itsdangerous-1.1.0\n","  Attempting uninstall: torchvision\n","    Found existing installation: torchvision 0.11.1+cu111\n","    Uninstalling torchvision-0.11.1+cu111:\n","      Successfully uninstalled torchvision-0.11.1+cu111\n","  Attempting uninstall: Flask\n","    Found existing installation: Flask 1.1.4\n","    Uninstalling Flask-1.1.4:\n","      Successfully uninstalled Flask-1.1.4\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchtext 0.11.0 requires torch==1.10.0, but you have torch 1.9.0 which is incompatible.\n","torchaudio 0.10.0+cu111 requires torch==1.10.0, but you have torch 1.9.0 which is incompatible.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n","Successfully installed Flask-2.0.1 Jinja2-3.0.3 Werkzeug-2.0.2 itsdangerous-2.0.1 torch-1.9.0 torchvision-0.10.0\n"]}]},{"cell_type":"code","metadata":{"id":"1BCfmSJUh5M9","executionInfo":{"status":"ok","timestamp":1638690221179,"user_tz":-540,"elapsed":6,"user":{"displayName":"부계정박준영","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13767636744278294407"}}},"source":["from flask import Flask\n","app = Flask(__name__)\n","\n","\n","@app.route('/')\n","def hello():\n","    return 'Hello World!'"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LwIq_foLjHT4","executionInfo":{"status":"ok","timestamp":1638690250466,"user_tz":-540,"elapsed":729,"user":{"displayName":"부계정박준영","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13767636744278294407"}},"outputId":"60ef5045-ab87-4194-a408-8e3f04421a52"},"source":["# app.py\n","!FLASK_ENV=development FLASK_APP=app.py flask run"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":[" * Serving Flask app 'app.py' (lazy loading)\n"," * Environment: development\n"," * Debug mode: on\n","Usage: flask run [OPTIONS]\n","\n","Error: Could not import 'app'.\n"]}]},{"cell_type":"code","metadata":{"id":"__4LsFCmjNeV"},"source":["from flask import Flask, jsonify\n","app = Flask(__name__)\n","\n","\n","# app.py에 predict 넣음\n","@app.route('/predict', methods=['POST'])\n","def predict():\n","    return jsonify({'class_id': 'IMAGE_NET_XXX', 'class_name': 'Cat'})"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1UlEb5OKjgvc"},"source":["# image 준비"]},{"cell_type":"code","metadata":{"id":"KqBiMyxcjcjJ","executionInfo":{"status":"ok","timestamp":1638690350026,"user_tz":-540,"elapsed":809,"user":{"displayName":"부계정박준영","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13767636744278294407"}}},"source":["import io\n","\n","import torchvision.transforms as transforms\n","from PIL import Image\n","\n","def transform_image(image_bytes):\n","    my_transforms = transforms.Compose([transforms.Resize(255),\n","                                        transforms.CenterCrop(224),\n","                                        transforms.ToTensor(),\n","                                        transforms.Normalize(\n","                                            [0.485, 0.456, 0.406],\n","                                            [0.229, 0.224, 0.225])])\n","    image = Image.open(io.BytesIO(image_bytes))\n","    return my_transforms(image).unsqueeze(0)"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":245},"id":"SYfsvRqqjcbs","executionInfo":{"status":"error","timestamp":1638690522571,"user_tz":-540,"elapsed":305,"user":{"displayName":"부계정박준영","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13767636744278294407"}},"outputId":"c4bac8fb-a4c4-4200-d6c3-f582254a8a3d"},"source":["# 이미지 바꿈\n","with open(\"../_static/img/sample_file.jpeg\", 'rb') as f:\n","    image_bytes = f.read()\n","    tensor = transform_image(image_bytes=image_bytes)\n","    print(tensor)"],"execution_count":6,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-fbeb69457b37>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 이미지 바꿈\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../_static/img/sample_file.jpeg\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mimage_bytes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_bytes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimage_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../_static/img/sample_file.jpeg'"]}]},{"cell_type":"markdown","metadata":{"id":"xftQzuROjsxD"},"source":["# 예측"]},{"cell_type":"code","metadata":{"id":"1zTgR9GVju07"},"source":["from torchvision import models\n","\n","model = models.densenet121(pretrained=True)\n","model.eval()\n","\n","\n","def get_prediction(image_bytes):\n","    tensor = transform_image(image_bytes=image_bytes)\n","    outputs = model.forward(tensor)\n","    _, y_hat = outputs.max(1)\n","    return y_hat"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gQyuJWdmj9VU"},"source":["# Yhat은 class label을 보여주기에 이름으로 바꾸어야함\n","import json\n","\n","imagenet_class_index = json.load(open('../_static/imagenet_class_index.json'))\n","\n","def get_prediction(image_bytes):\n","    tensor = transform_image(image_bytes=image_bytes)\n","    outputs = model.forward(tensor)\n","    _, y_hat = outputs.max(1)\n","    predicted_idx = str(y_hat.item())\n","    return imagenet_class_index[predicted_idx]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"d61KRugQjubk"},"source":["with open(\"../_static/img/sample_file.jpeg\", 'rb') as f:\n","    image_bytes = f.read()\n","    print(get_prediction(image_bytes=image_bytes))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DGMiCNjpkb6F"},"source":["# API 서버와 model통합"]},{"cell_type":"code","metadata":{"id":"-OabcAZHkgXM","executionInfo":{"status":"ok","timestamp":1638690597109,"user_tz":-540,"elapsed":583,"user":{"displayName":"부계정박준영","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13767636744278294407"}}},"source":["from flask import request\n","\n","@app.route('/predict', methods=['POST'])\n","def predict():\n","    if request.method == 'POST':\n","        file = request.files['file'] # request해서 파일 불러옴\n","        img_bytes = file.read() # 파일을 바이트로 바꿈\n","        class_id, class_name = get_prediction(image_bytes=img_bytes)\n","        return jsonify({'class_id': class_id, 'class_name': class_name})"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":282},"id":"uwEFOR_mkgIE","executionInfo":{"status":"error","timestamp":1638690661609,"user_tz":-540,"elapsed":397,"user":{"displayName":"부계정박준영","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13767636744278294407"}},"outputId":"1e5e7d2a-06c0-4a97-e0a8-660f8221b739"},"source":["import io\n","import json\n","\n","from torchvision import models\n","import torchvision.transforms as transforms\n","from PIL import Image\n","from flask import Flask, jsonify, request\n","\n","\n","app = Flask(__name__)\n","imagenet_class_index = json.load(open('<PATH/TO/.json/FILE>/imagenet_class_index.json')) # josn load\n","model = models.densenet121(pretrained=True)\n","model.eval()\n","\n","\n","def transform_image(image_bytes):\n","    my_transforms = transforms.Compose([transforms.Resize(255),\n","                                        transforms.CenterCrop(224),\n","                                        transforms.ToTensor(),\n","                                        transforms.Normalize(\n","                                            [0.485, 0.456, 0.406],\n","                                            [0.229, 0.224, 0.225])])\n","    image = Image.open(io.BytesIO(image_bytes))\n","    return my_transforms(image).unsqueeze(0)\n","\n","\n","def get_prediction(image_bytes):\n","    tensor = transform_image(image_bytes=image_bytes)\n","    outputs = model.forward(tensor)\n","    _, y_hat = outputs.max(1)\n","    predicted_idx = str(y_hat.item())\n","    return imagenet_class_index[predicted_idx]\n","\n","\n","@app.route('/predict', methods=['POST'])\n","def predict():\n","    if request.method == 'POST':\n","        file = request.files['file']\n","        img_bytes = file.read()\n","        class_id, class_name = get_prediction(image_bytes=img_bytes)\n","        return jsonify({'class_id': class_id, 'class_name': class_name})\n","\n","\n","if __name__ == '__main__':\n","    app.run()"],"execution_count":8,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-bc2c3dc27d57>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mapp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFlask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mimagenet_class_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'<PATH/TO/.json/FILE>/imagenet_class_index.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# josn load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdensenet121\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '<PATH/TO/.json/FILE>/imagenet_class_index.json'"]}]},{"cell_type":"markdown","metadata":{"id":"5vrubeVFk2pG"},"source":["### upgrad 방향\n","\n","- /predict : request에 항상 이미지 파일이 있다고 가정\n","\n","- 사용자들이 이미지 이외의 것을 보낼 수 있기에 예외 처리\n","- 모델이 많은 수의 이미지를 인식할 지라도 모든 이미지를 인식하는 것은 아님. 그러므로, 이를 방지할 필요있다\n","- UI 추가 가능"]},{"cell_type":"code","metadata":{"id":"GipjZXAgkyF1"},"source":[""],"execution_count":null,"outputs":[]}]}