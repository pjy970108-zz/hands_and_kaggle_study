{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"REINFORCEMENT LEARNING (DQN) TUTORIAL.ipynb","provenance":[],"authorship_tag":"ABX9TyP6cwAZcJ10IM+9K+fl1D1z"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"-2mMk37tHHJ_"},"source":["# DQN 튜토리얼\n","\n","<br>\n","\n","매번 time step마다 reward 1더한다. 그리고 pole이 떨어지거나 카트가 2.4 만큼 떨어지면 학습 끝남. 이는 더 나은 시나리오 수행은 오래 지속되고 더 많이 축적되는 것을 의마한다.\n","\n","<br>\n","NN은 task를 장면을 보면서 수행할 수 있다. 그래서 우리는 patch of the screen centered를 사용한다.\n"]},{"cell_type":"code","metadata":{"id":"37Ah-ySJG3B3","executionInfo":{"status":"ok","timestamp":1638685504740,"user_tz":-540,"elapsed":495,"user":{"displayName":"부계정박준영","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13767636744278294407"}}},"source":["import gym\n","import math\n","import random\n","import numpy as np\n","import matplotlib\n","import matplotlib.pyplot as plt\n","from collections import namedtuple, deque\n","from itertools import count\n","from PIL import Image\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","import torchvision.transforms as T\n","\n","\n","env = gym.make('CartPole-v0').unwrapped\n","\n","# set up matplotlib\n","is_ipython = 'inline' in matplotlib.get_backend()\n","if is_ipython:\n","    from IPython import display\n","\n","plt.ion()\n","\n","# if gpu is to be used\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_qBgHnC7IPxV"},"source":["### Replay memory\n","\n","우리는 DQN을 학습하면서 agent가 관측한 변화를 저장한다. 임의추출 방식으로, DQN 학습을 안정화 할 수 있다.\n","\n","- 필요한 classses\n","\n","    1) Transition : 환경에서 하나의 변화로 대표되는 튜플, map(state, action)해서 (next_state, reward)한다. \n","    \n","    2) Replay memory : 최근 이동을 잡는다.  "]},{"cell_type":"code","metadata":{"id":"V4jbqUmjIJby","executionInfo":{"status":"ok","timestamp":1638685505205,"user_tz":-540,"elapsed":13,"user":{"displayName":"부계정박준영","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13767636744278294407"}}},"source":["Transition = namedtuple('Transition',\n","                        ('state', 'action', 'next_state', 'reward'))\n","\n","\n","class ReplayMemory(object):\n","\n","    def __init__(self, capacity):\n","        self.memory = deque([],maxlen=capacity)\n","\n","    def push(self, *args):\n","        \"\"\"Save a transition\"\"\"\n","        self.memory.append(Transition(*args))\n","\n","    def sample(self, batch_size):\n","        return random.sample(self.memory, batch_size)\n","\n","    def __len__(self):\n","        return len(self.memory)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"KYLRLzlYIJRk","executionInfo":{"status":"ok","timestamp":1638685505207,"user_tz":-540,"elapsed":14,"user":{"displayName":"부계정박준영","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13767636744278294407"}}},"source":["class DQN(nn.Module):\n","\n","    def __init__(self, h, w, outputs):\n","        super(DQN, self).__init__()\n","        self.conv1 = nn.Conv2d(3, 16, kernel_size=5, stride=2)\n","        self.bn1 = nn.BatchNorm2d(16)\n","        self.conv2 = nn.Conv2d(16, 32, kernel_size=5, stride=2)\n","        self.bn2 = nn.BatchNorm2d(32)\n","        self.conv3 = nn.Conv2d(32, 32, kernel_size=5, stride=2)\n","        self.bn3 = nn.BatchNorm2d(32)\n","\n","        # 선형 input connections의 수는 conv2d layer의 아웃풋에 의존함\n","        def conv2d_size_out(size, kernel_size = 5, stride = 2):\n","            return (size - (kernel_size - 1) - 1) // stride  + 1\n","        convw = conv2d_size_out(conv2d_size_out(conv2d_size_out(w)))\n","        convh = conv2d_size_out(conv2d_size_out(conv2d_size_out(h)))\n","        linear_input_size = convw * convh * 32\n","        self.head = nn.Linear(linear_input_size, outputs)\n","\n","    # 다음 행동을 결절할 하나의 요소를 불러움h\n","    # 최적화 동안 tensor를 리턴함\n","    def forward(self, x):\n","        x = x.to(device)\n","        x = F.relu(self.bn1(self.conv1(x)))\n","        x = F.relu(self.bn2(self.conv2(x)))\n","        x = F.relu(self.bn3(self.conv3(x)))\n","        return self.head(x.view(x.size(0), -1))"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AeRgfD0IJ9g3"},"source":["## input 추출"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":472},"id":"cJlyUrM1J7o4","executionInfo":{"status":"error","timestamp":1638685505209,"user_tz":-540,"elapsed":15,"user":{"displayName":"부계정박준영","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13767636744278294407"}},"outputId":"9981a9ed-18c1-46fd-c16b-a0581c0ddcf3"},"source":["# 랜더링\n","resize = T.Compose([T.ToPILImage(),\n","                    T.Resize(40, interpolation=Image.CUBIC),\n","                    T.ToTensor()])\n","\n","\n","def get_cart_location(screen_width):\n","    world_width = env.x_threshold * 2\n","    scale = screen_width / world_width\n","    return int(env.state[0] * scale + screen_width / 2.0)  # 카트의 중간\n","\n","def get_screen():\n","    # gym에 의해 요청된 screen is 400x600x3, 그러나 가끔 800*1200*3\n","    # Transpose it into torch order (CHW).\n","    screen = env.render(mode='rgb_array').transpose((2, 0, 1))\n","    # 카트는 lower half이다. 그래서 strip off한다. \n","    _, screen_height, screen_width = screen.shape\n","    screen = screen[:, int(screen_height*0.4):int(screen_height * 0.8)]\n","    view_width = int(screen_width * 0.6)\n","    cart_location = get_cart_location(screen_width)\n","    if cart_location < view_width // 2: # 화면/2 보다 cart location 이 작으면\n","        slice_range = slice(view_width) # slice한다\n","    elif cart_location > (screen_width - view_width // 2):\n","        slice_range = slice(-view_width, None)\n","    else:\n","        slice_range = slice(cart_location - view_width // 2,\n","                            cart_location + view_width // 2)\n","    # 엣지를 자름, 그래서 정사각형의 이미지 가짐\n","    screen = screen[:, :, slice_range]\n","    # 실수를 torch로 바꿈    screen = np.ascontiguousarray(screen, dtype=np.float32) / 255\n","    screen = torch.from_numpy(screen)\n","    # Resize, and add a batch dimension (BCHW)\n","    return resize(screen).unsqueeze(0)\n","\n","\n","env.reset()\n","plt.figure()\n","plt.imshow(get_screen().cpu().squeeze(0).permute(1, 2, 0).numpy(),\n","           interpolation='none')\n","plt.title('Example extracted screen')\n","plt.show()"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n","  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n"]},{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-e4bb70e0d175>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m plt.imshow(get_screen().cpu().squeeze(0).permute(1, 2, 0).numpy(),\n\u001b[0m\u001b[1;32m     39\u001b[0m            interpolation='none')\n\u001b[1;32m     40\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Example extracted screen'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-8-e4bb70e0d175>\u001b[0m in \u001b[0;36mget_screen\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# gym에 의해 요청된 screen is 400x600x3, 그러나 가끔 800*1200*3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# Transpose it into torch order (CHW).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mscreen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rgb_array'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0;31m# 카트는 lower half이다. 그래서 strip off한다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen_height\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen_width\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gym/envs/classic_control/cartpole.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m             \u001b[0;32mfrom\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassic_control\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrendering\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrendering\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mViewer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscreen_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen_height\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m             \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mcartwidth\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcartwidth\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcartheight\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mcartheight\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gym/envs/classic_control/rendering.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mpyglet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgl\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     raise ImportError('''\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyglet/gl/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0;32melif\u001b[0m \u001b[0mcompat_platform\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'darwin'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcocoa\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCocoaConfig\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mConfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m \u001b[0;32mdel\u001b[0m \u001b[0mbase\u001b[0m  \u001b[0;31m# noqa: F821\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'base' is not defined"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 0 Axes>"]},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"d0xkfYcINlqB"},"source":["## 학습\n","\n","- select_action : epsilon greedy policy역할\n","- plot durations : 매피소드마다 시간을 ploting 해줌"]},{"cell_type":"code","metadata":{"id":"_EuEEg18K2HT","executionInfo":{"status":"aborted","timestamp":1638685505207,"user_tz":-540,"elapsed":9,"user":{"displayName":"부계정박준영","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13767636744278294407"}}},"source":["BATCH_SIZE = 128\n","GAMMA = 0.999\n","EPS_START = 0.9\n","EPS_END = 0.05\n","EPS_DECAY = 200\n","TARGET_UPDATE = 10\n","\n","# 초기화\n","init_screen = get_screen()\n","_, _, screen_height, screen_width = init_screen.shape\n","\n","n_actions = env.action_space.n\n","\n","policy_net = DQN(screen_height, screen_width, n_actions).to(device)\n","target_net = DQN(screen_height, screen_width, n_actions).to(device)\n","target_net.load_state_dict(policy_net.state_dict())\n","target_net.eval()\n","\n","optimizer = optim.RMSprop(policy_net.parameters())\n","memory = ReplayMemory(10000)\n","\n","\n","steps_done = 0\n","\n","\n","# 행동 선택\n","def select_action(state):\n","    global steps_done\n","    sample = random.random()\n","    eps_threshold = EPS_END + (EPS_START - EPS_END) * \\\n","        math.exp(-1. * steps_done / EPS_DECAY)\n","    steps_done += 1\n","    if sample > eps_threshold:\n","        with torch.no_grad():\n","            return policy_net(state).max(1)[1].view(1, 1)\n","    else:\n","        return torch.tensor([[random.randrange(n_actions)]], device=device, dtype=torch.long)\n","\n","\n","episode_durations = []\n","\n","# 지속시간 plot\n","def plot_durations():\n","    plt.figure(2)\n","    plt.clf()\n","    durations_t = torch.tensor(episode_durations, dtype=torch.float)\n","    plt.title('Training...')\n","    plt.xlabel('Episode')\n","    plt.ylabel('Duration')\n","    plt.plot(durations_t.numpy())\n","\n","    if len(durations_t) >= 100:\n","        means = durations_t.unfold(0, 100, 1).mean(1).view(-1)\n","        means = torch.cat((torch.zeros(99), means))\n","        plt.plot(means.numpy())\n","\n","    plt.pause(0.001)  # pause a bit so that plots are updated\n","    if is_ipython:\n","        display.clear_output(wait=True)\n","        display.display(plt.gcf())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Mw-xQZLNPb6X"},"source":["## Training loop\n","\n","1. 모든 텐서를 concat, Q(), V()를 합침\n","그 뒤에 loss에 넣음\n","2. 만약 S는 종료 state면, V(S)=0으로함"]},{"cell_type":"code","metadata":{"id":"jK0DAo9UPa1Y","executionInfo":{"status":"aborted","timestamp":1638685505208,"user_tz":-540,"elapsed":10,"user":{"displayName":"부계정박준영","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13767636744278294407"}}},"source":["def optimize_model():\n","    if len(memory) < BATCH_SIZE:\n","        return\n","    transitions = memory.sample(BATCH_SIZE)\n","    batch = Transition(*zip(*transitions))\n","\n","    non_final_mask = torch.tensor(tuple(map(lambda s: s is not None,\n","                                          batch.next_state)), device=device, dtype=torch.bool)\n","    non_final_next_states = torch.cat([s for s in batch.next_state\n","                                                if s is not None])\n","    state_batch = torch.cat(batch.state)\n","    action_batch = torch.cat(batch.action)\n","    reward_batch = torch.cat(batch.reward)\n","\n","    # Q(s_t, a) 계산, 그런 뒤 행동 선택\n","    state_action_values = policy_net(state_batch).gather(1, action_batch)\n","\n","\n","    # 모든 상황에 V(s_{t+1}) 계산. non_final_next_states에 대한 행동의 기대값이 기반\n","    next_state_values = torch.zeros(BATCH_SIZE, device=device)\n","    next_state_values[non_final_mask] = target_net(non_final_next_states).max(1)[0].detach()\n","    # Q 기대값 계산\n","    expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n","\n","    # Huber loss 계산\n","    criterion = nn.SmoothL1Loss()\n","    # 기대값과 state_action_value간 loss 비교\n","    loss = criterion(state_action_values, expected_state_action_values.unsqueeze(1))\n","\n","    # Optimize the model\n","    optimizer.zero_grad()\n","    loss.backward()\n","    for param in policy_net.parameters():\n","        param.grad.data.clamp_(-1, 1)\n","    optimizer.step()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DSAHNWo9QFxK","executionInfo":{"status":"aborted","timestamp":1638685505208,"user_tz":-540,"elapsed":10,"user":{"displayName":"부계정박준영","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13767636744278294407"}}},"source":["num_episodes = 50\n","for i_episode in range(num_episodes):\n","    # Initialize the environment and state\n","    env.reset()\n","    last_screen = get_screen()\n","    current_screen = get_screen()\n","    state = current_screen - last_screen\n","    for t in count():\n","        # 행위 선택\n","        action = select_action(state)\n","        _, reward, done, _ = env.step(action.item())\n","        reward = torch.tensor([reward], device=device)\n","\n","        # 새로운 상태 관측\n","        last_screen = current_screen\n","        current_screen = get_screen()\n","        if not done:\n","            next_state = current_screen - last_screen\n","        else:\n","            next_state = None\n","\n","        # 저장\n","        memory.push(state, action, next_state, reward)\n","\n","        # 다음 행동 이동\n","        state = next_state\n","\n","        optimize_model()\n","        if done:\n","            episode_durations.append(t + 1)\n","            plot_durations()\n","            break\n","    # Uupdate\n","    if i_episode % TARGET_UPDATE == 0:\n","        target_net.load_state_dict(policy_net.state_dict())\n","\n","print('Complete')\n","env.render()\n","env.close()\n","plt.ioff()\n","plt.show()"],"execution_count":null,"outputs":[]}]}